[33m2245862[m[33m ([m[1;36mHEAD[m[33m -> [m[1;32mmain[m[33m, [m[1;31morigin/main[m[33m)[m feat: Revert to Ollama-only setup and add dynamic timeout management - Remove LM Studio integration files (ai_server_manager.js, ai_server_config.js) - Restore direct Ollama API calls in server.js - Set DEFAULT_MODEL to gpt-oss:20b - Implement getModelTimeout() function for model-specific timeouts - Update all chat endpoints to use dynamic timeouts - Remove AI server selection UI from improved_ui.html
[33mb3a043c[m  Complete LM Studio integration with AI Server Manager - Fixed OLLAMA_URL reference errors - Added proper error handling for AI server responses - Fixed model display issues in UI - Added AI server switching endpoints - Updated server configuration and logging - Both Ollama and LM Studio now fully supported
[33m9fdc60b[m docs: Fix Live Demo preview and gallery link - Use static preview image linking to hosted GIF; update 'View Full UI Gallery' anchor to #-screenshots--ui-gallery
